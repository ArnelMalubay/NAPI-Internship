{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks shows the performance evaluation of the EfficientNet-based model made by the Computational Systems Biology Laboratory. We first load some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, gc\n",
    "import re, time, json\n",
    "import datetime\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "\n",
    "from  ast import literal_eval\n",
    "\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "import timm\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the directory for our pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.hub.set_dir(\"/project/dsc-is/malubay-a\")  \n",
    "model_names = timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define our Enet class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "model_name = 'efficientnet_b0'\n",
    "data_config = timm.data.resolve_data_config({}, model=model_name, verbose=True)\n",
    "\n",
    "class Enet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Enet,self).__init__()\n",
    "        self.model  = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "                                nn.Linear(1280, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(512, 128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(128, 2),\n",
    "                                )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b0 = Enet().cuda()\n",
    "\n",
    "saved_model = \"ef0_sokuwan.pth\"\n",
    "if(os.path.exists(saved_model)):\n",
    "    model_b0.load_state_dict(torch.load(saved_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Transformations and Utility Functions for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    ,\n",
    "    \"own\": transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data,label,transform = data_transforms['test']):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.label = label\n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image=Image.fromarray(np.uint16(image))\n",
    "        image=image.convert(\"RGB\")\n",
    "        image=np.asarray(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        image = self.normalize(image)\n",
    "    \n",
    "\n",
    "        if self.transform!=None:\n",
    "            out_data = self.transform(image)\n",
    "        \n",
    "        else:\n",
    "            out_data = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(self.label[idx]).float()\n",
    "\n",
    "        return out_data,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50297, 256, 256)\n",
      "(32700, 256, 256)\n",
      "(82997, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "dir_data = \"/project/dsc-is/napi\"\n",
    "\n",
    "if not \"data_all\" in globals():\n",
    "    tmp = np.load(os.path.join(dir_data, \"dat0\", \"pix_w256_1.npz\"))\n",
    "    data1 = tmp['arr_0']\n",
    "    print(data1.shape)\n",
    "    tmp = np.load(os.path.join(dir_data, \"dat0\", \"pix_w256_2.npz\"))\n",
    "    data2 = tmp['arr_0']\n",
    "    print(data2.shape)\n",
    "    \n",
    "    data_all = np.concatenate((data1,data2), axis=0) \n",
    "    del data1\n",
    "    del data2\n",
    "\n",
    "print(data_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis1 = pd.read_csv(os.path.join(dir_data, \"dat0\", \"diagnosis_new.txt\"), sep='\\t', header=None)\n",
    "yyy_scoliosis = (diagnosis1.iloc[:,4]==\"æœ‰\").to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the model to predict on our dataset. Note that our model has two output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Mydatasets(data_all, yyy_scoliosis)\n",
    "dataloader = DataLoader(datasets, batch_size=10, shuffle=False)\n",
    "\n",
    "model_b0.eval()\n",
    "out_all = []\n",
    "for data, label in dataloader:\n",
    "    with torch.no_grad():\n",
    "        out_tmp = model_b0(data.cuda())\n",
    "        out_all.append(out_tmp.cpu().numpy())\n",
    "        \n",
    "out_all = np.concatenate(out_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this model has two output units, we use softmax to get a \"score\" function which will be used to compute for the predicted labels and ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(out):\n",
    "    tmp = np.exp(out[:,0])+np.exp(out[:,1])\n",
    "    return(np.exp(out[:,1]) / tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = softmax(out_all)\n",
    "preds = scores >= 0.5\n",
    "preds = preds.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get the indices of true positives, false positives, false negatives, and true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_true_positive = np.where(np.logical_and(preds == 1, yyy_scoliosis == 1))[0]\n",
    "idx_false_positive = np.where(np.logical_and(preds == 1, yyy_scoliosis == 0))[0]\n",
    "idx_false_negative = np.where(np.logical_and(preds == 0, yyy_scoliosis == 1))[0]\n",
    "idx_true_negative = np.where(np.logical_and(preds == 0, yyy_scoliosis == 0))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive Diagnosis</th>\n",
       "      <th>Negative Diagnosis</th>\n",
       "      <th>Totals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive Prediction</th>\n",
       "      <td>1235</td>\n",
       "      <td>3529</td>\n",
       "      <td>4764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Prediction</th>\n",
       "      <td>73</td>\n",
       "      <td>78160</td>\n",
       "      <td>78233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Totals</th>\n",
       "      <td>1308</td>\n",
       "      <td>81689</td>\n",
       "      <td>82997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Positive Diagnosis  Negative Diagnosis  Totals\n",
       "Positive Prediction                1235                3529    4764\n",
       "Negative Prediction                  73               78160   78233\n",
       "Totals                             1308               81689   82997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(columns = ['Positive Diagnosis', 'Negative Diagnosis', 'Totals'], \n",
    "                                index = ['Positive Prediction', 'Negative Prediction', 'Totals'],\n",
    "                                data = [[idx_true_positive.shape[0], idx_false_positive.shape[0], idx_true_positive.shape[0] + idx_false_positive.shape[0]],\n",
    "                                        [idx_false_negative.shape[0], idx_true_negative.shape[0], idx_false_negative.shape[0] + idx_true_negative.shape[0]],\n",
    "                                        [idx_true_positive.shape[0] + idx_false_negative.shape[0], idx_false_positive.shape[0] + idx_true_negative.shape[0], 82997]])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute for some classification metrics. As seen below, our precision and recall values are quite low. This low precision value is compensated by a relatively high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.66%\n",
      "Precision: 25.924%\n",
      "Recall: 94.419%\n",
      "F1-Score: 40.679%\n",
      "ROC_AUC: 98.725%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(yyy_scoliosis, preds),3)}%')\n",
    "print(f'Precision: {round(100*precision_score(yyy_scoliosis, preds),3)}%')\n",
    "print(f'Recall: {round(100*recall_score(yyy_scoliosis, preds),3)}%')\n",
    "print(f'F1-Score: {round(100*f1_score(yyy_scoliosis, preds),3)}%')\n",
    "print(f'ROC_AUC: {round(100*roc_auc_score(yyy_scoliosis, scores),3)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
